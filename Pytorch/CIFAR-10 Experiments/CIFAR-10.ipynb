{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import floor\n",
    "import talwar_ai.data_utils as data_tools\n",
    "import talwar_ai.train_utils as model_tools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import gc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "data_dir = 'data/cifar_data/'\n",
    "train_dir = 'data/train/'\n",
    "valid_dir = 'data/valid/'\n",
    "test_dir = 'data/test/'\n",
    "has_header = True\n",
    "data_file = 'trainLabels.csv'\n",
    "train_file = 'train_labels.csv'\n",
    "valid_file = 'valid_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean/std stats from Jeremy Howard's CIFAR-10 notebook.\n",
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "num_classes = len(classes)\n",
    "stats = {'mean' : np.array([ 0.4914 ,  0.48216,  0.44653]), 'std' : np.array([ 0.24703,  0.24349,  0.26159])}\n",
    "data_path = {'train' : train_dir,\n",
    "            'valid' : valid_dir,\n",
    "            'test' : test_dir}\n",
    "csvfile = {'train' : train_file,\n",
    "          'valid' : valid_file,\n",
    "          'test' : None}\n",
    "shuffle = {'train' :  True,\n",
    "          'valid' : False,\n",
    "          'test' : False}\n",
    "max_read = {'train' : 1286,\n",
    "           'valid' : 64,\n",
    "           'test' : 0}\n",
    "img_size = 32\n",
    "batch_size = 4\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1286 train images.\n",
      "Read 64 valid images.\n",
      "Read 0 test images.\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "data_transforms = {'train' : transforms.Compose([\n",
    "                        transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),\n",
    "                        transforms.RandomHorizontalFlip(),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(stats['mean'], stats['std'])]),\n",
    "                  'valid' : transforms.Compose([transforms.ToTensor(),\n",
    "                                               transforms.Normalize(stats['mean'], stats['std'])]),\n",
    "                  'test' : transforms.Compose([transforms.ToTensor(),\n",
    "                                              transforms.Normalize(stats['mean'], stats['std'])])}\n",
    "image_datasets = {x : data_tools.SingleLabelImages(x, data_path[x], csvfile[x], classes, '.png', \n",
    "                                    data_transforms[x], max_read[x]) for x in ['train', 'valid', 'test']}\n",
    "image_loaders = {x : DataLoader(image_datasets[x], shuffle=shuffle[x], batch_size=batch_size, \n",
    "                                num_workers=num_workers) for x in ['train', 'valid', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = image_datasets['train'].__getitem__(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns an image in numpy array form with shape (H, W, C)\n",
    "def DenormalizeImage(img_tensor, mean, std):\n",
    "    return np.clip(img_tensor.numpy().transpose((1,2,0))*std + mean, 0.0, 1.0)\n",
    "plt.rcParams['figure.dpi'] = 30\n",
    "_ = plt.imshow(DenormalizeImage(sample['image'], stats['mean'], stats['std']))\n",
    "plt.show()\n",
    "print('Label: {}'.format(classes[sample['label']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=False)\n",
    "model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "#optimizer = optim.Adam(model.parameters())\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "trainer = model_tools.Trainer(device, model, criterion, optimizer, '')\n",
    "trainer.Train(image_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f90996de90435e817605b9c4c4df69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n",
      "0.00011000000000000002\n",
      "0.00012100000000000003\n",
      "0.00013310000000000004\n",
      "0.00014641000000000006\n",
      "0.00016105100000000005\n",
      "0.0001771561000000001\n",
      "0.00019487171000000014\n",
      "0.00021435888100000016\n",
      "0.0002357947691000002\n",
      "0.0002593742460100002\n",
      "0.0002853116706110003\n",
      "0.0003138428376721003\n",
      "0.0003452271214393104\n",
      "0.00037974983358324147\n",
      "0.0004177248169415656\n",
      "0.0004594972986357222\n",
      "0.0005054470284992945\n",
      "0.000555991731349224\n",
      "0.0006115909044841464\n",
      "0.0006727499949325611\n",
      "0.0007400249944258173\n",
      "0.0008140274938683991\n",
      "0.0008954302432552391\n",
      "0.000984973267580763\n",
      "0.0010834705943388394\n",
      "0.0011918176537727234\n",
      "0.001310999419149996\n",
      "0.0014420993610649957\n",
      "0.0015863092971714953\n",
      "0.001744940226888645\n",
      "0.0019194342495775097\n",
      "0.0021113776745352608\n",
      "0.002322515441988787\n",
      "0.0025547669861876662\n",
      "0.002810243684806433\n",
      "0.0030912680532870765\n",
      "0.003400394858615784\n",
      "0.0037404343444773632\n",
      "0.0041144777789251\n",
      "0.00452592555681761\n",
      "0.004978518112499371\n",
      "0.005476369923749309\n",
      "0.006024006916124241\n",
      "0.006626407607736666\n",
      "0.007289048368510333\n",
      "0.008017953205361366\n",
      "0.008819748525897503\n",
      "0.009701723378487254\n",
      "0.01067189571633598\n",
      "0.011739085287969579\n",
      "0.01291299381676654\n",
      "0.014204293198443194\n",
      "0.015624722518287514\n",
      "0.01718719477011627\n",
      "0.018905914247127894\n",
      "0.020796505671840687\n",
      "0.022876156239024757\n",
      "0.025163771862927235\n",
      "0.027680149049219963\n",
      "0.030448163954141957\n",
      "0.03349298034955615\n",
      "0.036842278384511776\n",
      "0.04052650622296296\n",
      "0.04457915684525926\n",
      "0.04903707252978519\n",
      "0.05394077978276371\n",
      "0.05933485776104009\n",
      "0.0652683435371441\n",
      "0.07179517789085851\n",
      "0.07897469567994436\n",
      "0.08687216524793882\n",
      "0.09555938177273271\n",
      "0.10511531995000599\n",
      "0.1156268519450066\n",
      "0.12718953713950726\n",
      "0.139908490853458\n",
      "0.1538993399388038\n",
      "0.16928927393268423\n",
      "0.18621820132595263\n",
      "0.20484002145854793\n",
      "0.22532402360440273\n",
      "0.247856425964843\n",
      "0.27264206856132733\n",
      "0.29990627541746007\n",
      "0.32989690295920615\n",
      "0.3628865932551268\n",
      "0.3991752525806395\n",
      "0.4390927778387035\n",
      "0.4830020556225739\n",
      "0.5313022611848313\n",
      "0.5844324873033144\n",
      "0.642875736033646\n",
      "0.7071633096370106\n",
      "0.7778796406007118\n",
      "0.8556676046607831\n",
      "0.9412343651268613\n",
      "1.0353578016395475\n",
      "1.1388935818035024\n",
      "1.2527829399838528\n",
      "1.3780612339822382\n",
      "1.5158673573804622\n",
      "1.6674540931185087\n",
      "1.8341995024303595\n",
      "2.0176194526733955\n",
      "2.2193813979407353\n",
      "2.441319537734809\n",
      "2.6854514915082905\n",
      "2.9539966406591196\n",
      "3.249396304725032\n",
      "3.574335935197535\n",
      "3.9317695287172887\n",
      "4.324946481589018\n",
      "4.75744112974792\n",
      "5.233185242722713\n",
      "5.756503766994984\n",
      "6.332154143694484\n",
      "6.965369558063933\n",
      "7.661906513870326\n",
      "8.42809716525736\n",
      "9.270906881783096\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "nn_model = model_tools.NNModel('resnet34', 'sgd', 'cross_entropy', 10,pre_trained=True)\n",
    "nn_model.freezeParams(freeze_modules=['layer3', 'layer4', 'layer1'])\n",
    "nn_model.exploreLR()\n",
    "#model = models.resnet18(pretrained=False)\n",
    "# for name, module in model.named_modules():\n",
    "#     if (name == 'layer1'):\n",
    "#         for p in module.parameters():\n",
    "#             p.requires_grad = False\n",
    "# for n, p in nn_model.model.named_parameters():\n",
    "#     print(n, p.requires_grad)\n",
    "trainer = model_tools.Trainer(device, nn_model.model, nn_model.criterion, nn_model.optimizer, nn_model.scheduler, '')\n",
    "trainer.train(image_loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RecordLoss(mode, loss_dict):\n",
    "    with open('loss_history.csv', mode) as f:\n",
    "        fieldnames = ['iter', 'train_loss', 'val_loss']\n",
    "        writer = csv.writer(f, lineterminator='\\n')\n",
    "        if (mode == 'w'):\n",
    "            writer.writerow(fieldnames)\n",
    "        for num_iter, loss in loss_dict.items():\n",
    "            writer.writerow([num_iter, loss[0], loss[1]])\n",
    "            \n",
    "def EvalStats(model, criterion, image_loader, num_items=1, req_stats=['loss']):\n",
    "    num_updates = 0\n",
    "    loss_stat= 0.0\n",
    "    stats = {}\n",
    "    torch.set_grad_enabled(False)\n",
    "    for sample in iter(image_loader):\n",
    "        inputs, labels = sample['image'].to(device), sample['label'].long().to(device)\n",
    "        outputs = model(inputs)\n",
    "        if ('loss' in req_stats):\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss_stat += loss.item()\n",
    "        num_updates += 1\n",
    "    torch.set_grad_enabled(True)\n",
    "    if ('loss' in req_stats):\n",
    "        if (num_updates == 0):\n",
    "            loss_stat = 0.0\n",
    "        else:\n",
    "            loss_stat = round(loss_stat/num_updates*num_items, 2)\n",
    "        stats.update({'loss' : loss_stat})\n",
    "    return stats\n",
    "    \n",
    "    \n",
    "def TrainModel(model, criterion, optimizer, model_path, num_epochs=5, stat_freq=1, checkpoint_freq=500):\n",
    "    progress_bar = tqdm(total=num_epochs)\n",
    "    loss_history = {'train' : [],\n",
    "                   'valid' : []}\n",
    "    loss_dict = {}\n",
    "    # set best_val_loss as loss on the valid set with initial state of the model\n",
    "    stats = EvalStats(model, criterion, image_loaders['valid'], num_items=1, req_stats=['loss'])\n",
    "    best_val_loss = stats['loss']\n",
    "    \n",
    "    # Train the model\n",
    "    torch.set_grad_enabled(True)\n",
    "    num_updates = 0\n",
    "    num_iter = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(image_loaders['train'], 0):\n",
    "            num_iter += 1\n",
    "            if (i%5 == 4):\n",
    "                progress_bar.set_description('e {} i {}'.format(epoch + 1, i + 1))\n",
    "            inputs, labels = data['image'].to(device), data['label'].long().to(device)\n",
    "            # forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # update statistics\n",
    "            running_loss += loss.item()\n",
    "            num_updates += 1\n",
    "            gc.collect()\n",
    "            # checl validation error after every 'stat_freq' no. of iterations\n",
    "            if (i%stat_freq == (stat_freq - 1)):\n",
    "                # Calculate validation loss \n",
    "                torch.set_grad_enabled(False)\n",
    "                stats = EvalStats(model, criterion, image_loaders['valid'], num_items=1, req_stats=['loss'])\n",
    "                val_loss = stats['loss']\n",
    "                if (val_loss < best_val_loss):\n",
    "                    SaveCheckpoint(model.state_dict(), optimizer.state_dict(), epoch + 1, \n",
    "                                   model_path.replace('.mdl', '_BEST.mdl'))\n",
    "                    best_val_loss = val_loss\n",
    "                train_loss = running_loss/num_updates*1\n",
    "                progress_bar.set_postfix(train_loss='{:.2f}'.format(train_loss), \n",
    "                                         val_loss='{:.2f}'.format(val_loss))\n",
    "                loss_dict.update({num_iter : [round(train_loss, 2), round(val_loss, 2)]})\n",
    "                running_loss = 0.0\n",
    "                num_updates = 0\n",
    "                torch.set_grad_enabled(True)\n",
    "            if (i%checkpoint_freq == (checkpoint_freq - 1)):\n",
    "                SaveCheckpoint(model.state_dict(), optimizer.state_dict(), epoch + 1,\n",
    "                               model_path.replace('.mdl', '_Epoch {} Iter {}.mdl'.format(epoch + 1, i + 1)))\n",
    "        gc.collect()\n",
    "        progress_bar.update(1)\n",
    "        #Record loss at end of each epoch\n",
    "        mode = 'a'\n",
    "        if (epoch == 0):\n",
    "            mode = 'w'\n",
    "        RecordLoss(mode, loss_dict)\n",
    "        loss_dict = {}\n",
    "    progress_bar.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRPlots(num_trial=5, iter_per_trial=10):\n",
    "    torch.set_grad_enabled(True)\n",
    "    update_freq = 1\n",
    "    plots = {}\n",
    "    for trial in range(num_trial):\n",
    "        lr = 10**(-np.random.uniform(1, 3))\n",
    "        model, optimizer, criterion = GetModel(lr)\n",
    "        running_loss = 0.0\n",
    "        num_updates  = 0\n",
    "        loss_record = []\n",
    "        for i, data in zip(range(iter_per_trial), image_loaders['train']):\n",
    "            inputs, labels = data['image'].to(device), data['label'].long().to(device)\n",
    "            # forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # update statistics\n",
    "            running_loss += loss.item()\n",
    "            num_updates += 1\n",
    "            if (i%update_freq == 0):\n",
    "                loss_record += [round(running_loss/num_updates, 2)]\n",
    "                running_loss = 0.0\n",
    "                num_updates = 0\n",
    "        plots.update({round(lr, 5) : loss_record})\n",
    "    return plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Setup\n",
    "def GetModel(lr):    \n",
    "    model = models.resnet18(pretrained=False)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return model, optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = LRPlots(num_trial=5, iter_per_trial=100)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "for lr, losses in plots.items():\n",
    "    plt.plot(np.arange(len(losses)), losses, label='lr={:.5f}'.format(lr))\n",
    "_ = plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, criterion = GetModel(lr=0.004)\n",
    "model = TrainModel(model, criterion, optimizer, 'test.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1e9\n",
    "if(10%a == 0):\n",
    "    print(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
