{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import floor\n",
    "import talwar_ai.data_utils as data_tools\n",
    "import talwar_ai.train_utils as model_tools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import gc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "data_dir = 'data/cifar_data/'\n",
    "train_dir = 'data/train/'\n",
    "valid_dir = 'data/valid/'\n",
    "test_dir = 'data/test/'\n",
    "has_header = True\n",
    "data_file = 'trainLabels.csv'\n",
    "train_file = 'train_labels.csv'\n",
    "valid_file = 'valid_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean/std stats from Jeremy Howard's CIFAR-10 notebook.\n",
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "num_classes = len(classes)\n",
    "stats = {'mean' : np.array([ 0.4914 ,  0.48216,  0.44653]), 'std' : np.array([ 0.24703,  0.24349,  0.26159])}\n",
    "data_path = {'train' : train_dir,\n",
    "            'valid' : valid_dir,\n",
    "            'test' : test_dir}\n",
    "csvfile = {'train' : train_file,\n",
    "          'valid' : valid_file,\n",
    "          'test' : None}\n",
    "shuffle = {'train' :  True,\n",
    "          'valid' : False,\n",
    "          'test' : False}\n",
    "max_read = {'train' : 1286,\n",
    "           'valid' : 64,\n",
    "           'test' : 0}\n",
    "img_size = 32\n",
    "batch_size = 32\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1286 train images.\n",
      "Read 64 valid images.\n",
      "Read 0 test images.\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "data_transforms = {'train' : transforms.Compose([\n",
    "                        transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),\n",
    "                        transforms.RandomHorizontalFlip(),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(stats['mean'], stats['std'])]),\n",
    "                  'valid' : transforms.Compose([transforms.ToTensor(),\n",
    "                                               transforms.Normalize(stats['mean'], stats['std'])]),\n",
    "                  'test' : transforms.Compose([transforms.ToTensor(),\n",
    "                                              transforms.Normalize(stats['mean'], stats['std'])])}\n",
    "image_datasets = {x : data_tools.SingleLabelImages(x, data_path[x], csvfile[x], classes, '.png', \n",
    "                                    data_transforms[x], max_read[x]) for x in ['train', 'valid', 'test']}\n",
    "image_loaders = {x : DataLoader(image_datasets[x], shuffle=shuffle[x], batch_size=batch_size, \n",
    "                                num_workers=num_workers) for x in ['train', 'valid', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = image_datasets['train'].__getitem__(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns an image in numpy array form with shape (H, W, C)\n",
    "def DenormalizeImage(img_tensor, mean, std):\n",
    "    return np.clip(img_tensor.numpy().transpose((1,2,0))*std + mean, 0.0, 1.0)\n",
    "plt.rcParams['figure.dpi'] = 30\n",
    "_ = plt.imshow(DenormalizeImage(sample['image'], stats['mean'], stats['std']))\n",
    "plt.show()\n",
    "print('Label: {}'.format(classes[sample['label']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=False)\n",
    "model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "#optimizer = optim.Adam(model.parameters())\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "trainer = model_tools.Trainer(device, model, criterion, optimizer, '')\n",
    "trainer.Train(image_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40b0698bc014498a0696bbc52290ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_model = model_tools.NNModel('resnet34', 'sgd', 'cross_entropy', 10,pre_trained=True)\n",
    "nn_model.freezeParams(freeze_modules=['layer3', 'layer4', 'layer1'])\n",
    "#model = models.resnet18(pretrained=False)\n",
    "# for name, module in model.named_modules():\n",
    "#     if (name == 'layer1'):\n",
    "#         for p in module.parameters():\n",
    "#             p.requires_grad = False\n",
    "# for n, p in nn_model.model.named_parameters():\n",
    "#     print(n, p.requires_grad)\n",
    "trainer = model_tools.Trainer(device, nn_model.model, nn_model.criterion, nn_model.optimizer, '')\n",
    "trainer.train(image_loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RecordLoss(mode, loss_dict):\n",
    "    with open('loss_history.csv', mode) as f:\n",
    "        fieldnames = ['iter', 'train_loss', 'val_loss']\n",
    "        writer = csv.writer(f, lineterminator='\\n')\n",
    "        if (mode == 'w'):\n",
    "            writer.writerow(fieldnames)\n",
    "        for num_iter, loss in loss_dict.items():\n",
    "            writer.writerow([num_iter, loss[0], loss[1]])\n",
    "            \n",
    "def EvalStats(model, criterion, image_loader, num_items=1, req_stats=['loss']):\n",
    "    num_updates = 0\n",
    "    loss_stat= 0.0\n",
    "    stats = {}\n",
    "    torch.set_grad_enabled(False)\n",
    "    for sample in iter(image_loader):\n",
    "        inputs, labels = sample['image'].to(device), sample['label'].long().to(device)\n",
    "        outputs = model(inputs)\n",
    "        if ('loss' in req_stats):\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss_stat += loss.item()\n",
    "        num_updates += 1\n",
    "    torch.set_grad_enabled(True)\n",
    "    if ('loss' in req_stats):\n",
    "        if (num_updates == 0):\n",
    "            loss_stat = 0.0\n",
    "        else:\n",
    "            loss_stat = round(loss_stat/num_updates*num_items, 2)\n",
    "        stats.update({'loss' : loss_stat})\n",
    "    return stats\n",
    "    \n",
    "    \n",
    "def TrainModel(model, criterion, optimizer, model_path, num_epochs=5, stat_freq=1, checkpoint_freq=500):\n",
    "    progress_bar = tqdm(total=num_epochs)\n",
    "    loss_history = {'train' : [],\n",
    "                   'valid' : []}\n",
    "    loss_dict = {}\n",
    "    # set best_val_loss as loss on the valid set with initial state of the model\n",
    "    stats = EvalStats(model, criterion, image_loaders['valid'], num_items=1, req_stats=['loss'])\n",
    "    best_val_loss = stats['loss']\n",
    "    \n",
    "    # Train the model\n",
    "    torch.set_grad_enabled(True)\n",
    "    num_updates = 0\n",
    "    num_iter = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(image_loaders['train'], 0):\n",
    "            num_iter += 1\n",
    "            if (i%5 == 4):\n",
    "                progress_bar.set_description('e {} i {}'.format(epoch + 1, i + 1))\n",
    "            inputs, labels = data['image'].to(device), data['label'].long().to(device)\n",
    "            # forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # update statistics\n",
    "            running_loss += loss.item()\n",
    "            num_updates += 1\n",
    "            gc.collect()\n",
    "            # checl validation error after every 'stat_freq' no. of iterations\n",
    "            if (i%stat_freq == (stat_freq - 1)):\n",
    "                # Calculate validation loss \n",
    "                torch.set_grad_enabled(False)\n",
    "                stats = EvalStats(model, criterion, image_loaders['valid'], num_items=1, req_stats=['loss'])\n",
    "                val_loss = stats['loss']\n",
    "                if (val_loss < best_val_loss):\n",
    "                    SaveCheckpoint(model.state_dict(), optimizer.state_dict(), epoch + 1, \n",
    "                                   model_path.replace('.mdl', '_BEST.mdl'))\n",
    "                    best_val_loss = val_loss\n",
    "                train_loss = running_loss/num_updates*1\n",
    "                progress_bar.set_postfix(train_loss='{:.2f}'.format(train_loss), \n",
    "                                         val_loss='{:.2f}'.format(val_loss))\n",
    "                loss_dict.update({num_iter : [round(train_loss, 2), round(val_loss, 2)]})\n",
    "                running_loss = 0.0\n",
    "                num_updates = 0\n",
    "                torch.set_grad_enabled(True)\n",
    "            if (i%checkpoint_freq == (checkpoint_freq - 1)):\n",
    "                SaveCheckpoint(model.state_dict(), optimizer.state_dict(), epoch + 1,\n",
    "                               model_path.replace('.mdl', '_Epoch {} Iter {}.mdl'.format(epoch + 1, i + 1)))\n",
    "        gc.collect()\n",
    "        progress_bar.update(1)\n",
    "        #Record loss at end of each epoch\n",
    "        mode = 'a'\n",
    "        if (epoch == 0):\n",
    "            mode = 'w'\n",
    "        RecordLoss(mode, loss_dict)\n",
    "        loss_dict = {}\n",
    "    progress_bar.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRPlots(num_trial=5, iter_per_trial=10):\n",
    "    torch.set_grad_enabled(True)\n",
    "    update_freq = 1\n",
    "    plots = {}\n",
    "    for trial in range(num_trial):\n",
    "        lr = 10**(-np.random.uniform(1, 3))\n",
    "        model, optimizer, criterion = GetModel(lr)\n",
    "        running_loss = 0.0\n",
    "        num_updates  = 0\n",
    "        loss_record = []\n",
    "        for i, data in zip(range(iter_per_trial), image_loaders['train']):\n",
    "            inputs, labels = data['image'].to(device), data['label'].long().to(device)\n",
    "            # forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # update statistics\n",
    "            running_loss += loss.item()\n",
    "            num_updates += 1\n",
    "            if (i%update_freq == 0):\n",
    "                loss_record += [round(running_loss/num_updates, 2)]\n",
    "                running_loss = 0.0\n",
    "                num_updates = 0\n",
    "        plots.update({round(lr, 5) : loss_record})\n",
    "    return plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Setup\n",
    "def GetModel(lr):    \n",
    "    model = models.resnet18(pretrained=False)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return model, optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = LRPlots(num_trial=5, iter_per_trial=100)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "for lr, losses in plots.items():\n",
    "    plt.plot(np.arange(len(losses)), losses, label='lr={:.5f}'.format(lr))\n",
    "_ = plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, criterion = GetModel(lr=0.004)\n",
    "model = TrainModel(model, criterion, optimizer, 'test.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1e9\n",
    "if(10%a == 0):\n",
    "    print(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
